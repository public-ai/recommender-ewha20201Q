{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i><b>Public-AI</b></i>\n",
    "\n",
    "### ✎&nbsp;&nbsp;week 4. DNN Basis\n",
    "\n",
    "# Section 2. Keras 이해하기\n",
    "\n",
    "### _Objective_\n",
    "\n",
    "* Tensorflow의 Deep Learning API인 Keras를 단계 별로 살펴보며, 어떤 설계 구조를 가지고 있는지를 살펴 보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [ 예제 모델 : 4층 신경망 ] \n",
    "---\n",
    "\n",
    "\n",
    "<img src=\"https://imgur.com/U5QmvFo.png\" width=\"500\" > "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. `Layer` \n",
    "\n",
    "딥러닝에서의 `층`은 연산의 단위입니다. `층` 단위로 연산이 전파되고, 가중치가 관리됩니다. 이러한 층의 형태는 사람이 설계해야 하는데, 위와 같이 unit 수, activation의 종류, bias의 유무가 바로 사람이 설계해야 하는 요소, Hyper-Parameter입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) 레이어 생성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "hidden1_layer = Dense(5, activation='relu')\n",
    "hidden2_layer = Dense(5, activation='relu')\n",
    "hidden3_layer = Dense(5, activation='relu')\n",
    "output_layer = Dense(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) 레이어의 hyperparameter 가져오기 \n",
    "\n",
    "이러한 Hyper Parameter는 `.get_config()`을 통해 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden3_layer.get_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) `Weight` 생성하기\n",
    "\n",
    "각 은닉층 별로 Weight는 어떤 식으로 구성되어야 할까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"은닉층 1: \", hidden1_layer.get_weights())\n",
    "print(\"은닉층 2: \", hidden2_layer.get_weights())\n",
    "print(\"은닉층 3: \", hidden3_layer.get_weights())\n",
    "print(\"출력층  : \", output_layer.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아예 Weight가 없다고 나옵니다. 그 이유는 무엇일까요? 바로 \"입력의 갯수\"가 정해져 있지 않았기 때문입니다. 각 은닉층의 Weight의 크기는 (# 입력층 내 유닛의 수, # 유닛의 수)로 결정되는데, 각 층 별 입력이 몇개의 유닛으로 이루어져있는지를 아직 지정하지 않았습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `build` : Layer 내 Weight를 구성하기\n",
    "\n",
    "그래서 별도로 강제로 `build`를 동작시키면, 가중치가 결정됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1_layer.build((None, 3))\n",
    "\n",
    "hidden1_layer.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "입력층의 갯수가 커지면, 당연히 weight의 크기도 커집니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1_layer.build((None, 5))\n",
    "\n",
    "hidden1_layer.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "혹은 첫번째 연산 시의 입력값 형태에 맞춰서 Weight가 초기화됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1_layer = Dense(5, activation='relu')\n",
    "hidden1_layer.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력값 예시\n",
    "X = tf.constant([[0.2,0.5,0.7],\n",
    "                 [0.3,0.6,0.2,],\n",
    "                 [0.1,-.3,-.2]], tf.float32)\n",
    "\n",
    "hidden1_layer(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1_layer.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "당연한 얘기이지만 가중치 내 갯수와 맞지 않은 입력값이 들어가면 아래와 같이 Error를 반환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_x = tf.constant([[0.2,0.5,0.7,1.2],\n",
    "                 [0.3,0.6,0.2,2.3],\n",
    "                 [0.1,-.3,-.2,-.5]], tf.float32)\n",
    "\n",
    "hidden1_layer(wrong_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) `Layer`을 통해 연산하기\n",
    "\n",
    "`Layer`가 선언되었으면, 그이후로 Layer의 인스턴스는 하나의 Function과 같이 동작한다고 생각하면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = tf.constant([[0.2,0.5,0.7],\n",
    "                 [0.3,0.6,0.2,],\n",
    "                 [0.1,-.3,-.2]], tf.float32)\n",
    "\n",
    "X2 = tf.constant([[0.3,0.6,0.2,],\n",
    "                  [0.2,0.5,0.7],\n",
    "                  [-.3,-.5,0.7]], tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z1 = hidden1_layer(X1)\n",
    "print(Z1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z2 = hidden1_layer(X2)\n",
    "print(Z2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) `Layer` 내 가중치를 학습시키기\n",
    "\n",
    "가중치를 학습시키기 위해서는 순전파와 역전파를 알고 있어야 합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = tf.constant([[0.2,0.5,0.7],\n",
    "                 [0.3,0.6,0.2,],\n",
    "                 [0.1,-.3,-.2]], tf.float32)\n",
    "\n",
    "X2 = tf.constant([[0.3,0.6,0.2,],\n",
    "                  [0.2,0.5,0.7],\n",
    "                  [-.3,-.5,0.7]], tf.float32)\n",
    "\n",
    "Y_true = tf.constant([[1.2],[-0.5],[0.3]], tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 은닉층 구성하기\n",
    "hidden1_layer = Dense(5, activation='relu')\n",
    "hidden2_layer = Dense(5, activation='relu')\n",
    "hidden3_layer = Dense(1)\n",
    "\n",
    "# 순전파 진행하기\n",
    "with tf.GradientTape() as tape:\n",
    "    Z1 = hidden1_layer(X1)\n",
    "    Z2 = hidden2_layer(Z1)\n",
    "    Y_pred = hidden3_layer(Z2)    \n",
    "    \n",
    "    loss = tf.reduce_mean((Y_true - Y_pred)**2)\n",
    "\n",
    "# 모든 가중치 가져오기\n",
    "weights = [\n",
    "    *hidden1_layer.trainable_weights,\n",
    "    *hidden2_layer.trainable_weights,\n",
    "    *hidden3_layer.trainable_weights\n",
    "]    \n",
    "# 가중치의 기울기 계산하기\n",
    "grads = tape.gradient(loss, weights)\n",
    "\n",
    "# 경사하강법 적용하기\n",
    "lr = 1e-4\n",
    "for weight, grad in zip(weights, grads):\n",
    "    weight.assign_sub(lr*grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. `Model`\n",
    "\n",
    "위와 같이 `Layer` 단위로 연산할 수 있게 만든 것이 `Keras`. 그래서 연산과 가중치로 이루어져 있다고 생각하면 됩니다. 하지만 딥러닝은 수십~수백개의 Layer로 이루어져 있기 때문에, 수십~수백개의 Layer를 관리하는 것이 필요합니다. 그것이 바로 `Model`입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) `Model`의 입력층, `Input`\n",
    "\n",
    "`Model`은 입력과 출력만을 결정하면, 내부 로직에 의해 관련된 `Layer`들을 모두 수집하여 관리합니다. 그래서 입력만을 관리하는 특수한 녀석이 따로 존재하고 이것이 바로 `Input`입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "\n",
    "inputs = Input((3,))\n",
    "\n",
    "# 은닉층 선언\n",
    "hidden1_layer = Dense(5, activation='relu', name='hidden_1')\n",
    "hidden2_layer = Dense(5, activation='relu', name='hidden_2')\n",
    "hidden3_layer = Dense(1, name='hidden_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1 = hidden1_layer(inputs)\n",
    "hidden2 = hidden2_layer(hidden1)\n",
    "hidden3 = hidden3_layer(hidden2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) 모델 선언하기\n",
    "\n",
    "모델은 선언하는 것은 간단합니다. `Input`층부터 이어져서 출력층까지의 연결을 만들 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "\n",
    "model = Model(inputs, hidden1)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs, hidden2)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs, hidden3)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 때 주의해야 하는 것은 `Input`층부터 시작해야 한다는 것입니다. 아니면 아래와 같이 에러를 반환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model(hidden1, hidden3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그럼 아래와 같이 중간층부터 시작하고 싶다면 새로운 Input층을 선언해준 후 연결해주어야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1_inputs = Input((5,))\n",
    "\n",
    "# 은닉층 연결하기\n",
    "hidden2 = hidden2_layer(hidden1_inputs)\n",
    "hidden3 = hidden3_layer(hidden2)\n",
    "\n",
    "model2 = Model(hidden1_inputs, hidden3)\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) 모델 내 레이어 가져오기\n",
    "\n",
    "`.get_layer`를 통해 간단히 가져올 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = model.get_layer('hidden_2')\n",
    "\n",
    "layer is hidden2_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = model.get_layer('hidden_3')\n",
    "\n",
    "layer is hidden3_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "해당 Layer의 출력 텐서를 가져오고 싶으면, `.output`을 이용하면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer.output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그리고 전체적인 레이어에 대한 정보는 `model.get_config()`로 가져올 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow에서 모델의 구조는 내부적으로 `Graph`의 형태로 관리됩니다. 하지만 Keras API에서는 config json 포맷으로 관리됩니다. 그래서 Tensorflow를 저장할 때에는 모델의 연산을 정의하는 Graph와 모델 내 가중치를 의미하는 Checkpoint를 따로 저장했다면, Keras에서는 모델의 연산을 정의하는 Config 와 모델 내 가중치를 의미하는 weights를 따로 저장합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) 모델에서 관리하고 있는 가중치 가져오기\n",
    "\n",
    "현재 모델에서의 가중치 중에서 학습해야할 가중치는 `trainable_variables`에 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.trainable = True\n",
    "\n",
    "model.trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.trainable = False\n",
    "\n",
    "model.trainable_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "대신 학습대상이 아닌 가중치들은 `non_trianable_variables`에 들어갑니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.non_trainable_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리는 종종 Pretrain Model 등을 이용할 때, 특정 층만 학습에서 제외해야 할 때가 있습니다. 그런 경우 우리는 Model 내 Layer 별로 trainable를 지정해줄 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.trainable = True\n",
    "model.get_layer('hidden_1').trainable = False\n",
    "model.get_layer('hidden_2').trainable = True\n",
    "model.get_layer('hidden_3').trainable = False\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.get_weights()`로 가져오는 것은 모델 자체 내 현재 가중치의 값을 넘파이로 가져올 때 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) 모델 전체 순전파하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = tf.constant([[0.2,0.5,0.7],\n",
    "                 [0.3,0.6,0.2,],\n",
    "                 [0.1,-.3,-.2]], tf.float32)\n",
    "\n",
    "X2 = tf.constant([[0.3,0.6,0.2,],\n",
    "                  [0.2,0.5,0.7],\n",
    "                  [-.3,-.5,0.7]], tf.float32)\n",
    "\n",
    "Y_true = tf.constant([[1.2],[-0.5],[0.3]], tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model(X1)\n",
    "Y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`predict`는 추론환경에서 이용하기 위해 만들어진 특수한 연산입니다. 바로 Numpy로 반환하게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(X1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (5) 모델 역전파하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    # model.predict(X1)하면 동작하지 않음\n",
    "    Y_pred = model(X1)\n",
    "    Loss = tf.reduce_mean((Y_pred-Y_true)**2)\n",
    "\n",
    "# 역전파로 기울기 구하기\n",
    "grads = tape.gradient(Loss, model.trainable_weights)\n",
    "\n",
    "# 경사하강법 적용하기\n",
    "lr = 1e-4\n",
    "for weight, grad in zip(model.trainable_weights, grads):\n",
    "    weight.assign_sub(lr*grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 과정에서 어떤 손실함수를 이용할지, 어떤 경사하강법을 이용할지, 어떤 Metricd으로 평가할지를 결정하게 됩니다. 이 과정을 케라스에서는 `compile`이라는 함수를 통해 일괄적으로 지정할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd',loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그리고 데이터를 통해 모델 내 가중치를 업데이트 하는 것은 바로 `fit`으로 진행하게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X, Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  \n",
    "\n",
    "---\n",
    "\n",
    "    Copyright(c) 2019 by Public AI. All rights reserved.<br>\n",
    "    Writen by PAI, SangJae Kang ( rocketgrowthsj@publicai.co.kr )  last updated on 2020/03/26\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.0",
   "language": "python",
   "name": "tf2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
